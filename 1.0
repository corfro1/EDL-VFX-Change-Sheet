import streamlit as st
import pandas as pd
import opentimelineio as otio # For EDL parsing
import opentimelineio.opentime as opentime # For timecode math
import io # For handling file uploads

# --- Paste the Python functions we discussed earlier here ---
# def parse_edl_with_markers(edl_file_content, frame_rate, ...): ...
# def parse_uploaded_csv(csv_file_content): ...
# def compare_data(current_edl_shots, previous_csv_data): ...
# (Including all their helper logic and correct import statements)

# --- Add the updated Python functions from our previous discussion ---
# Make sure these functions are defined before they are called in the Streamlit UI section

def parse_edl_with_markers(edl_file_content, frame_rate=23.976, vfx_marker_name_filter=None):
    parsed_shots = []
    try:
        # Use io.StringIO if edl_file_content is already a string
        # If edl_file_content is bytes (from Streamlit uploader), decode it
        if isinstance(edl_file_content, bytes):
            edl_file_content = edl_file_content.decode('utf-8-sig')

        timeline = otio.adapters.read_from_string(edl_file_content, rate=frame_rate)
        edl_title = timeline.name if timeline.name else "Default_Episode"

        for track in timeline.tracks:
            if not isinstance(track, otio.schema.Track):
                continue
            for clip in track:
                if not isinstance(clip, otio.schema.Clip):
                    continue
                vfx_id_from_marker = None
                for marker in clip.markers:
                    vfx_id_from_marker = marker.name # Assuming marker.name is the VFX ID
                    if vfx_id_from_marker:
                        break
                
                if vfx_id_from_marker:
                    shot_info = {}
                    shot_info["VFX ID"] = vfx_id_from_marker # Match CSV header
                    shot_info["Episode"] = edl_title

                    record_in_tc_obj = clip.source_range.start_time
                    record_out_tc_obj = clip.source_range.start_time + clip.source_range.duration - opentime.RationalTime(1, frame_rate)
                    shot_info["Record TC In"] = record_in_tc_obj.to_timecode()
                    shot_info["Record TC Out"] = record_out_tc_obj.to_timecode()

                    cmx_metadata = clip.metadata.get('cmx_3600', {})
                    src_in_str = cmx_metadata.get('source_in')
                    src_out_str = cmx_metadata.get('source_out')
                    source_tc_in_obj, source_tc_out_obj = None, None

                    if src_in_str and src_out_str:
                        try:
                            source_tc_in_obj = opentime.from_timecode(src_in_str, frame_rate)
                            source_tc_out_obj = opentime.from_timecode(src_out_str, frame_rate) # Assuming EDL source_out is inclusive
                        except: # Handle potential malformed timecode strings in EDL
                            pass 
                    
                    shot_info["Source TC In"] = source_tc_in_obj.to_timecode() if source_tc_in_obj else "N/A"
                    shot_info["Source TC Out"] = source_tc_out_obj.to_timecode() if source_tc_out_obj else "N/A"
                    
                    duration_frames = clip.source_range.duration.to_frames()
                    shot_info["Duration Frames"] = duration_frames
                    parsed_shots.append(shot_info)
        
        if not parsed_shots:
            return {"warning": "No clips with recognized VFX markers found."}
    except Exception as e:
        return {"error": f"Error parsing EDL: {e}"}
    return parsed_shots

def parse_uploaded_csv(csv_file_content):
    data = []
    try:
        if isinstance(csv_file_content, bytes):
            csv_file_content = csv_file_content.decode('utf-8-sig')
        
        csvfile = io.StringIO(csv_file_content)
        # Using pandas to read CSV for easier integration with Styler later
        df = pd.read_csv(csvfile)
        # Standardize column names to match what parse_edl_with_markers produces
        # Example: if CSV has "TC In", rename to "Record TC In"
        # This depends on your exact CSV headers. For now, assume they are compatible
        # or that you will preprocess df.columns here.
        # df.columns = [col.strip() for col in df.columns] # Clean whitespace from headers
        return df.to_dict('records') # Convert to list of dicts for compare_data
    except Exception as e:
        return {"error": f"Error parsing CSV: {e}"}
    return data

def compare_data(current_edl_shots_list_of_dicts, previous_csv_data_list_of_dicts):
    comparison_results_list = []
    # Convert previous data to a map for efficient lookup
    previous_data_map = {(item.get("VFX ID"), item.get("Episode")): item for item in previous_csv_data_list_of_dicts}

    fields_to_compare = ["Record TC In", "Record TC Out", "Source TC In", "Source TC Out", "Duration Frames"]

    for current_shot in current_edl_shots_list_of_dicts:
        current_vfx_id = current_shot.get("VFX ID")
        current_episode = current_shot.get("Episode")
        
        result_shot = current_shot.copy()
        result_shot["status"] = "new"
        result_shot["_changes"] = {} # Using _changes to store detailed change info

        previous_shot_dict = previous_data_map.get((current_vfx_id, current_episode))

        if previous_shot_dict:
            result_shot["status"] = "existing"
            has_changed = False
            for field in fields_to_compare:
                current_value = str(current_shot.get(field, "")).strip()
                previous_value = str(previous_shot_dict.get(field, "")).strip()
                
                if field == "Duration Frames": # Ensure numeric comparison for frames
                    try:
                        current_value_num = int(float(current_value)) if current_value else 0
                        previous_value_num = int(float(previous_value)) if previous_value else 0
                        if current_value_num != previous_value_num:
                            result_shot["_changes"][field] = {'old': previous_value, 'new': current_value}
                            has_changed = True
                    except ValueError: # If not convertible to int, compare as string
                        if current_value != previous_value:
                             result_shot["_changes"][field] = {'old': previous_value, 'new': current_value}
                             has_changed = True
                elif current_value != previous_value:
                    result_shot["_changes"][field] = {'old': previous_value, 'new': current_value}
                    has_changed = True
            
            if has_changed:
                result_shot["status"] = "updated"
            else:
                result_shot["status"] = "unchanged"
        comparison_results_list.append(result_shot)

    current_edl_ids_episodes = {(shot.get("VFX ID"), shot.get("Episode")) for shot in current_edl_shots_list_of_dicts}
    for prev_key, prev_shot_data in previous_data_map.items():
        if prev_key not in current_edl_ids_episodes:
            deleted_shot_info = prev_shot_data.copy()
            deleted_shot_info["status"] = "deleted"
            deleted_shot_info["_changes"] = {} 
            comparison_results_list.append(deleted_shot_info)
            
    return comparison_results_list

# --- Streamlit UI ---
st.set_page_config(layout="wide") # Use wide layout for tables
st.title("VFX EDL Comparator")

st.sidebar.header("Upload Files")
edl_file = st.sidebar.file_uploader("Upload AVID EDL File", type=["edl", "txt"])
csv_file = st.sidebar.file_uploader("Upload Previous CSV (Optional)", type=["csv"])

# User input for frame rate
# Common frame rates for video editing
frame_rates = [23.976, 24.0, 25.0, 29.97, 30.0, 50.0, 59.94, 60.0]
# Format them for display in the selectbox
formatted_frame_rates = [f"{fr:.3f}".rstrip('0').rstrip('.') if isinstance(fr, float) else str(fr) for fr in frame_rates]

selected_frame_rate_str = st.sidebar.selectbox(
    "Select EDL Frame Rate:",
    options=formatted_frame_rates,
    index=formatted_frame_rates.index("23.976") # Default to 23.976
)
frame_rate = float(selected_frame_rate_str)


if st.sidebar.button("Process Files"):
    if edl_file:
        edl_content = edl_file.read()
        st.subheader("EDL Parsing Results:")
        current_edl_data = parse_edl_with_markers(edl_content, frame_rate=frame_rate)

        if isinstance(current_edl_data, dict) and "error" in current_edl_data:
            st.error(f"EDL Parsing Error: {current_edl_data['error']}")
        elif isinstance(current_edl_data, dict) and "warning" in current_edl_data:
            st.warning(current_edl_data['warning'])
            st.info("No data to display from EDL.")
        elif not current_edl_data: # Empty list
            st.warning("No VFX shots found in the EDL based on markers.")
        else:
            # Convert to DataFrame for display and potential styling
            df_edl = pd.DataFrame(current_edl_data)
            
            # Define the desired column order based on your CSV example
            # "VFX ID or Code | Episode | Timecode In/Out of each VFX shot | Source Timecode In | Source Timecode Out | Duration of clip in Frames"
            # Map to the actual column names produced by parse_edl_with_markers
            desired_columns_edl = ["VFX ID", "Episode", "Record TC In", "Record TC Out", "Source TC In", "Source TC Out", "Duration Frames"]
            # Filter and reorder columns, handling missing ones
            df_edl_display = df_edl[[col for col in desired_columns_edl if col in df_edl.columns]]


            if csv_file:
                csv_content = csv_file.read()
                previous_csv_data_list = parse_uploaded_csv(csv_content)

                if isinstance(previous_csv_data_list, dict) and "error" in previous_csv_data_list:
                    st.error(f"CSV Parsing Error: {previous_csv_data_list['error']}")
                    st.subheader("Current EDL Data (No Comparison):")
                    st.dataframe(df_edl_display) # Show EDL data even if CSV fails
                else:
                    st.subheader("Comparison Results:")
                    # Ensure current_edl_data is a list of dicts for compare_data
                    comparison_results_list = compare_data(df_edl.to_dict('records'), previous_csv_data_list)
                    
                    if not comparison_results_list:
                        st.warning("No data to compare.")
                    else:
                        df_comparison = pd.DataFrame(comparison_results_list)

                        # Define the full desired column order for the comparison table including 'status'
                        # Make sure '_changes' is not in desired_columns_display
                        desired_columns_display = ["VFX ID", "Episode", "Record TC In", "Record TC Out", 
                                                   "Source TC In", "Source TC Out", "Duration Frames", "status"]
                        
                        # Reorder and select columns for display
                        # Fill missing values with "N/A" or empty string for display consistency
                        display_df_ordered = pd.DataFrame(columns=desired_columns_display)
                        for col in desired_columns_display:
                            if col in df_comparison.columns:
                                display_df_ordered[col] = df_comparison[col]
                            else: # If a key column like VFX ID is missing from some rows (e.g. deleted items from old CSV)
                                # try to get it from a common key, or fill
                                if col == "VFX ID" and "VFX ID" in df_comparison.columns: # Common key from original data
                                     display_df_ordered[col] = df_comparison["VFX ID"]
                                else:
                                     display_df_ordered[col] = "N/A"
                        display_df_ordered = display_df_ordered.fillna("N/A")


                        def highlight_changes(row):
                            # Base style for the row
                            styles = [''] * len(row) # Default no style
                            
                            # Apply row-level status styling
                            if row['status'] == 'updated':
                                styles = ['background-color: lightyellow'] * len(row)
                            elif row['status'] == 'new':
                                styles = ['background-color: lightgreen'] * len(row)
                            elif row['status'] == 'deleted':
                                styles = ['background-color: lightcoral; text-decoration: line-through'] * len(row)
                            
                            # Apply cell-specific highlighting for 'updated' rows
                            if row['status'] == 'updated' and isinstance(row.get('_changes'), dict):
                                for i, col_name in enumerate(row.index):
                                    if col_name in row['_changes']:
                                        styles[i] = 'background-color: lightyellow; color: red; font-weight: bold;'
                            return styles

                        styled_df = display_df_ordered.style.apply(highlight_changes, axis=1)
                        
                        st.dataframe(styled_df, height=(len(display_df_ordered) + 1) * 35 + 3) # Adjust height dynamically

            else: # No CSV file, just show EDL data
                st.subheader("Parsed EDL Data:")
                st.dataframe(df_edl_display)
    else:
        st.warning("Please upload an EDL file to process.")
